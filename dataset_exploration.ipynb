{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c620f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "044416cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/08 09:33:26 WARN Utils: Your hostname, julian-Latitude-7280 resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface wlp1s0)\n",
      "23/04/08 09:33:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/julian/spark-3.2.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/08 09:33:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/08 09:33:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/08 09:33:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/04/08 09:33:28 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Datasetexploration\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4456332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Datasetexploration</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe3b98fd880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaee8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\",\"true\").csv(\"/home/julian/FORD_GO_BIKE_PROJECT/Dataset-2017-fordgobike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df6ee328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- end_time: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: string (nullable = true)\n",
      " |-- start_station_longitude: string (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: string (nullable = true)\n",
      " |-- end_station_longitude: string (nullable = true)\n",
      " |-- bike_id: string (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: string (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5124920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decbc94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|member_gender|\n",
      "+-------------+\n",
      "|         null|\n",
      "|       Female|\n",
      "|        Other|\n",
      "|         Male|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('member_gender').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f28a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df == df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24891536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e054c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e99ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29326/2967414984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_29326/2967414984.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "# finding the number of null values in specific columns\n",
    "\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "df.select([count(when((isnan(c)) | (col(c).isnull()), c)).alias(c) for c in columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb8a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e768480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+-------+---------+-----------------+-------------+------+\n",
      "|start_time|end_time|start_station_id|start_station_name|start_station_latitude|start_station_longitude|end_station_id|end_station_name|end_station_latitude|end_station_longitude|bike_id|user_type|member_birth_year|member_gender|pyment|\n",
      "+----------+--------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+-------+---------+-----------------+-------------+------+\n",
      "|         0|       0|               0|                 0|                     0|                      0|             0|               0|                   0|                    0|      0|        0|                0|            0|     0|\n",
      "+----------+--------+----------------+------------------+----------------------+-----------------------+--------------+----------------+--------------------+---------------------+-------+---------+-----------------+-------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a33606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start_time',\n",
       " 'end_time',\n",
       " 'start_station_id',\n",
       " 'start_station_name',\n",
       " 'start_station_latitude',\n",
       " 'start_station_longitude',\n",
       " 'end_station_id',\n",
       " 'end_station_name',\n",
       " 'end_station_latitude',\n",
       " 'end_station_longitude',\n",
       " 'bike_id',\n",
       " 'user_type',\n",
       " 'member_birth_year',\n",
       " 'member_gender',\n",
       " 'pyment']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b630af",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29326/1419628619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'member_gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df.filter(df['member_gender'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d89716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types\n",
    "\n",
    "\n",
    "def getNullNanBlankCount(df: DataFrame) -> DataFrame: \n",
    "  \n",
    "  # get all the column names into a list\n",
    "  allColsList = df.columns\n",
    "  \n",
    "  # create an empty list to temporarily store column names and count values\n",
    "  listBuffer = []\n",
    "  \n",
    "  for field in allColsList:   \n",
    "    # count nulls\n",
    "    nullCondition = F.isnull(F.col(field))\n",
    "    nullCount = df.select(F.col(field)).filter(nullCondition).count()  \n",
    "    \n",
    "    # count nans\n",
    "    nanCondition = F.isnan(F.col(field))\n",
    "    nanCount = df.select(F.col(field)).filter(nanCondition).count()  \n",
    "    \n",
    "    # count blank/empty values\n",
    "    blankCount = df.select(F.col(field)).filter(F.col(field) == \" \").count()  \n",
    "     \n",
    "    # append column names and count values to the list\n",
    "    listBuffer.append((field, nullCount, nanCount, blankCount))\n",
    "\n",
    "  # convert listBuffer into a new dataframe\n",
    "  resDf = spark.createDataFrame(listBuffer, [\"table_column_name\", \"null_count\", \"nan_count\", \"blank_count\"])\n",
    " \n",
    "  return resDf\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdf.transform(getNullNanBlankCount()).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09893dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 142:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------+---------+-----------+\n",
      "|table_column_name      |null_count|nan_count|blank_count|\n",
      "+-----------------------+----------+---------+-----------+\n",
      "|start_time             |0         |0        |0          |\n",
      "|end_time               |0         |0        |0          |\n",
      "|start_station_id       |0         |0        |0          |\n",
      "|start_station_name     |0         |0        |0          |\n",
      "|start_station_latitude |0         |0        |0          |\n",
      "|start_station_longitude|0         |0        |0          |\n",
      "|end_station_id         |0         |0        |0          |\n",
      "|end_station_name       |0         |0        |0          |\n",
      "|end_station_latitude   |0         |0        |0          |\n",
      "|end_station_longitude  |0         |0        |0          |\n",
      "|bike_id                |0         |0        |0          |\n",
      "|user_type              |0         |0        |0          |\n",
      "|member_birth_year      |66541     |0        |0          |\n",
      "|member_gender          |66462     |0        |0          |\n",
      "|pyment                 |0         |0        |0          |\n",
      "+-----------------------+----------+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.transform(getNullNanBlankCount).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001e152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|     pyment|\n",
      "+-----------+\n",
      "| app wallet|\n",
      "|credit card|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 150:============================>                            (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('pyment').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3def23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('pyment').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2dd8a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- end_time: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: string (nullable = true)\n",
      " |-- start_station_longitude: string (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: string (nullable = true)\n",
      " |-- end_station_longitude: string (nullable = true)\n",
      " |-- bike_id: string (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: string (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c33c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 4) / 4]\r",
      "\r",
      "[Stage 11:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|avg(end_station_id)|\n",
      "+-------------------+\n",
      "|  92.18404079276506|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.agg({'end_station_id':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bb004de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99df87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('start_time','end_time').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ce68524",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4986/2027377795.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df1.withColumn('distance_travelled', haversine((df['start_station_latitude'],df['start_station_longitude']),\n\u001b[0m\u001b[1;32m      2\u001b[0m                     (df['end_station_latitude'],df['end_station_longitude']),unit=Unit.NAUTICAL_MILES ))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/haversine/haversine.py\u001b[0m in \u001b[0;36mhaversine\u001b[0;34m(point1, point2, unit, normalize, check)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mlat2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlng2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlng2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0m_ensure_lat_lon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlng1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0m_ensure_lat_lon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlng2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/haversine/haversine.py\u001b[0m in \u001b[0;36m_ensure_lat_lon\u001b[0;34m(lat, lon)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mEnsure\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mlatitude\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlongitude\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mproper\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAn\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mraised\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlat\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m90\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Latitude {lat} is out of range [-90, 90]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlon\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m180\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.2.3-bin-hadoop3.2/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         raise ValueError(\"Cannot convert column into bool: please use '&' for 'and', '|' for 'or', \"\n\u001b[0m\u001b[1;32m    908\u001b[0m                          \"'~' for 'not' when building DataFrame boolean expressions.\")\n\u001b[1;32m    909\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
     ]
    }
   ],
   "source": [
    "df1.withColumn('distance_travelled', haversine((df['start_station_latitude'],df['start_station_longitude']),\n",
    "                    (df['end_station_latitude'],df['end_station_longitude']),unit=Unit.NAUTICAL_MILES ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9ebf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting haversine\n",
      "  Using cached haversine-2.8.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805e2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between NYC and LA: 2445.6 miles\n"
     ]
    }
   ],
   "source": [
    "import haversine\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "# New York City coordinates\n",
    "nyc_coord = (40.7128, -74.0060)\n",
    "\n",
    "# Los Angeles coordinates\n",
    "la_coord = (34.0522, -118.2437)\n",
    "\n",
    "# Calculate distance between NYC and LA\n",
    "distance = haversine(nyc_coord, la_coord, unit=Unit.MILES)\n",
    "\n",
    "print(f\"Distance between NYC and LA: {distance:.1f} miles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386ffa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14da3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3e1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn('start_station_latitude',df['start_station_latitude'].cast(\"double\")).\\\n",
    "         withColumn('start_station_longitude',df['start_station_longitude'].cast(\"double\")).\\\n",
    "        withColumn('end_station_latitude',df['end_station_latitude'].cast(\"double\")).\\\n",
    "        withColumn('end_station_longitude',df['end_station_longitude'].cast(\"double\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b46505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64103382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785a5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType,DoubleType\n",
    "# defining the function you want \n",
    "def distance(lat1,long1,lat2,long2):\n",
    "    loc1 = (lat1,long1)\n",
    "    loc2 = (lat2,long2)\n",
    "    distance1 =haversine.haversine(loc1,loc2, Unit.KILOMETERS)\n",
    "    return distance1\n",
    "\n",
    "distanceUDF = udf(distance , DoubleType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3adb0759",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Resolved attribute(s) start_station_latitude#20,start_station_longitude#21,end_station_latitude#24,end_station_longitude#25 missing from start_time#16,end_time#17,start_station_id#18,start_station_name#19,start_station_latitude#61,start_station_longitude#77,end_station_id#22,end_station_name#23,end_station_latitude#93,end_station_longitude#109,bike_id#26,user_type#27,member_birth_year#28,member_gender#29,pyment#30 in operator !Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#93, end_station_longitude#109, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30, distance(start_station_latitude#20, start_station_longitude#21, end_station_latitude#24, end_station_longitude#25) AS distance_travelled#126]. Attribute(s) with the same name appear in the operation: start_station_latitude,start_station_longitude,end_station_latitude,end_station_longitude. Please check if the right attribute(s) are used.;\n!Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#93, end_station_longitude#109, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30, distance(start_station_latitude#20, start_station_longitude#21, end_station_latitude#24, end_station_longitude#25) AS distance_travelled#126]\n+- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#93, cast(end_station_longitude#25 as double) AS end_station_longitude#109, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n   +- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, cast(end_station_latitude#24 as double) AS end_station_latitude#93, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n      +- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, cast(start_station_longitude#21 as double) AS start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#24, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n         +- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, cast(start_station_latitude#20 as double) AS start_station_latitude#61, start_station_longitude#21, end_station_id#22, end_station_name#23, end_station_latitude#24, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n            +- Filter atleastnnonnulls(15, start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#20, start_station_longitude#21, end_station_id#22, end_station_name#23, end_station_latitude#24, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30)\n               +- Relation [start_time#16,end_time#17,start_station_id#18,start_station_name#19,start_station_latitude#20,start_station_longitude#21,end_station_id#22,end_station_name#23,end_station_latitude#24,end_station_longitude#25,bike_id#26,user_type#27,member_birth_year#28,member_gender#29,pyment#30] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24407/1530472761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df1.withColumn(\"distance_travelled\", distanceUDF(df['start_station_latitude'],df['start_station_longitude']\\\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                  \u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_station_latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                  ,df['end_station_longitude']))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.2.3-bin-hadoop3.2/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-3.2.3-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Resolved attribute(s) start_station_latitude#20,start_station_longitude#21,end_station_latitude#24,end_station_longitude#25 missing from start_time#16,end_time#17,start_station_id#18,start_station_name#19,start_station_latitude#61,start_station_longitude#77,end_station_id#22,end_station_name#23,end_station_latitude#93,end_station_longitude#109,bike_id#26,user_type#27,member_birth_year#28,member_gender#29,pyment#30 in operator !Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#93, end_station_longitude#109, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30, distance(start_station_latitude#20, start_station_longitude#21, end_station_latitude#24, end_station_longitude#25) AS distance_travelled#126]. Attribute(s) with the same name appear in the operation: start_station_latitude,start_station_longitude,end_station_latitude,end_station_longitude. Please check if the right attribute(s) are used.;\n!Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#93, end_station_longitude#109, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30, distance(start_station_latitude#20, start_station_longitude#21, end_station_latitude#24, end_station_longitude#25) AS distance_travelled#126]\n+- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#93, cast(end_station_longitude#25 as double) AS end_station_longitude#109, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n   +- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, start_station_longitude#77, end_station_id#22, end_station_name#23, cast(end_station_latitude#24 as double) AS end_station_latitude#93, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n      +- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#61, cast(start_station_longitude#21 as double) AS start_station_longitude#77, end_station_id#22, end_station_name#23, end_station_latitude#24, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n         +- Project [start_time#16, end_time#17, start_station_id#18, start_station_name#19, cast(start_station_latitude#20 as double) AS start_station_latitude#61, start_station_longitude#21, end_station_id#22, end_station_name#23, end_station_latitude#24, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30]\n            +- Filter atleastnnonnulls(15, start_time#16, end_time#17, start_station_id#18, start_station_name#19, start_station_latitude#20, start_station_longitude#21, end_station_id#22, end_station_name#23, end_station_latitude#24, end_station_longitude#25, bike_id#26, user_type#27, member_birth_year#28, member_gender#29, pyment#30)\n               +- Relation [start_time#16,end_time#17,start_station_id#18,start_station_name#19,start_station_latitude#20,start_station_longitude#21,end_station_id#22,end_station_name#23,end_station_latitude#24,end_station_longitude#25,bike_id#26,user_type#27,member_birth_year#28,member_gender#29,pyment#30] csv\n"
     ]
    }
   ],
   "source": [
    "df1.withColumn(\"distance_travelled\", distanceUDF(df['start_station_latitude'],df['start_station_longitude']\\\n",
    "                                                 ,df['end_station_latitude']\\\n",
    "                                                 ,df['end_station_longitude']))\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7101dab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "453159"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728d5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|start_station_latitude|\n",
      "+----------------------+\n",
      "|           37.77643482|\n",
      "|           37.78487208|\n",
      "|            37.8688126|\n",
      "|             37.866249|\n",
      "|            37.7766392|\n",
      "|            37.7766392|\n",
      "|             37.795001|\n",
      "|             37.795001|\n",
      "|            37.7737172|\n",
      "|           37.78588063|\n",
      "|             37.333955|\n",
      "|            37.7510171|\n",
      "|           37.79801364|\n",
      "|           37.79801364|\n",
      "|           37.87055533|\n",
      "|           37.80456235|\n",
      "|            37.7662102|\n",
      "|            37.3319323|\n",
      "|            37.8090126|\n",
      "|             37.765052|\n",
      "+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select('start_station_latitude').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b20534d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- end_time: string (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: double (nullable = true)\n",
      " |-- start_station_longitude: double (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: double (nullable = true)\n",
      " |-- end_station_longitude: double (nullable = true)\n",
      " |-- bike_id: string (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: string (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b102325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c770997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|trip_time|\n",
      "+---------+\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "|     null|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.withColumn('trip_time', df1['end_time'] - df1['start_time']).select('trip_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78027523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|start_time|\n",
      "+----------+\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select('start_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b86f632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df1 = df1.withColumn('start_time', to_timestamp(col('start_time'),\"HH:mm:ss.SSS\"))\\\n",
    "    .withColumn('end_time', to_timestamp(col('end_time'),\"HH:mm:ss.SSS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7119b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- end_time: timestamp (nullable = true)\n",
      " |-- start_station_id: string (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: double (nullable = true)\n",
      " |-- start_station_longitude: double (nullable = true)\n",
      " |-- end_station_id: string (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: double (nullable = true)\n",
      " |-- end_station_longitude: double (nullable = true)\n",
      " |-- bike_id: string (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: string (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Calculate Time difference in Seconds\n",
    "df2=df.withColumn('from_timestamp',to_timestamp(col('from_timestamp')))\\\n",
    "  .withColumn('end_timestamp', current_timestamp())\\\n",
    "  .withColumn('DiffInSeconds',col(\"end_timestamp\").cast(\"long\") - col('from_timestamp').cast(\"long\"))\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f32973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|DiffInSeconds|\n",
      "+-------------+\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "|         null|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#import pyspark.sql.functions as F\n",
    "\n",
    "df1.withColumn('DiffInSeconds',col(\"end_time\").cast(\"long\") - col('start_time').cast(\"long\"))\\\n",
    "                .select('DiffInSeconds').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc21ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|start_time|\n",
      "+----------+\n",
      "|   57:39.7|\n",
      "|   56:34.8|\n",
      "|   45:48.4|\n",
      "|   31:10.6|\n",
      "|   23:14.0|\n",
      "|   51:00.9|\n",
      "|   49:28.4|\n",
      "|   46:37.2|\n",
      "|   37:07.5|\n",
      "|   35:38.1|\n",
      "|   46:32.4|\n",
      "|   48:11.8|\n",
      "|   52:55.6|\n",
      "|   52:55.9|\n",
      "|   35:23.2|\n",
      "|   53:38.9|\n",
      "|   54:40.1|\n",
      "|   55:09.7|\n",
      "|   52:49.5|\n",
      "|   46:34.0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('start_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681717ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e9453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c7ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9dbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b1c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b24f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17d02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e082c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467f5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904629d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f96c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169360bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c9136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980fd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da0cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26605a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53647e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1e983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22524559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a22ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366b742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b11ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97999f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e6083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651db23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b205b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba24e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2411a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc7a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adf7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3e3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcab42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db65ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3158d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cbfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29baba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03746fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3514e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9996f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c43345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fc14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94642c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a44ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ae41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a1556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e68f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979790d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06206e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddae79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3c712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe187d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
